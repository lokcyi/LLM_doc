# LLM_doc
測試比較
1. "Humanity’s Last Exam"
Perplexity 測試中獲得了21.1%的分數
Gemini Thinking (6.2%)
Grok-2 (3.8%)
OpenAI的GPT-4o (3.3%)
僅落後於OpenAI的Deep Research (26.6%)。
2. SimpleQA基準測試中，Perplexity Deep Research 達到了 93.9% 的準確度，遠超其他領先模型的表現。

# Deep Research : 的目標是提供更深入的答案，並提供可受查證的引用資料，以滿足專業用戶的需求
## 
2025/02/14  Perplexity發布Deep Research，
- 一天可免費查5次
- 可以匯出為PDF檔案
- 速度與效率 : Perplexity 完成大部分研究任務僅需 1-3 分鐘，遠快於 ChatGPT 和 Gemini（5-30 分鐘）。支援 即時數據整合，能夠隨時獲取最新資訊。
## OpenAI

## Google Gemini AI ：

# 價格
## OpenAI
OpenAI的Deep Research，仍需要每月200美元的Pro版訂閱方案才能使用，即使OpenAI表示有計劃擴展到其他訂閱方案； 
## Perplexity的Deep Research
免費提供，免費用戶每天可以五次免費查詢，每月支付20美元的專業版訂戶可享有每天500次查詢，更快的處理速度。


## DeepSeek-r1

號稱「人工智慧的Sputnik（史普尼克）時刻」的DeepSeek-r1一出世就震撼全球科技界，不僅是因為「站在大師的肩膀上」透過學習AI的「蒸餾」技術，讓LLM在沒有充足GPU伺服器的前提下，也能達到與OpenAI、Google等模型的近似水準，訓練成本大幅降低。

DeepSeek甚至將技術「開源」開放模型源碼，只要有心誰都可以做出下一個「DeepSeek」，甚至超越它。DeepSeek-r1在數理、程式代碼領域上表現優異，同時，「中文」的理解與運用能力也遠勝Chatgpt。

而DeepSeek採用FP8（8位元浮點運算），可以在減少耗能的環境下達成目的，比如可以透過較低畫質辨識出一張圖片，減少儲存空間、降低成本外，仍可分析並給出結果。

## xAI Grok-3

## Anthropic推出Claude 3.7 Sonnet
全球首款混合推理模型 Claude 3.7 Sonnet 發布！大幅提升在數學、物理、程式設計等複雜任務表現
Claude 3.7 Sonnet（擴展思維版）適用於強邏輯推理和數學任務，而 Grok 3 Beta 和 DeepSeek R1 則在特定任務（推理、數學競賽）上表現更佳。
Claude 3.7 Sonnet： 全球首款雙模式混合推理模型，標準模式快速反應，擴展思考模式進行深度自我反思，在數學、物理和程式設計等複雜任務上表現卓越，注重實用導向，不必要拒絕減少 45%，強化程式碼協作能力

Claude Code： 直接在終端理解並操作程式碼庫，能一次完成需 45 分鐘以上的人工程式設計任務，專長於測試驅動開發、複雜偵錯和大規模程式碼重構，全面支援程式碼編輯、測試執行等核心開發流程
DeepSeek R1 在數學解題能力（97.3%）方面最強，同時在其他任務上也有不錯的表現。

在推理模型的最佳化過程中，Anthropic 減少了對數學和電腦科學競賽問題的側重，更專注於滿足企業對 LLM 的實際應用需求。

